{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1DKsBkqBScByyptex3UEZAqa8c0gaZbdY","timestamp":1730770221598},{"file_id":"1gFnwYEifoGn10Mbkg_opKyjKex8yK7jf","timestamp":1730753681006},{"file_id":"1u6CIA3YYLvO_Wljg2HlLDwuAWQTKSoBG","timestamp":1730750683432},{"file_id":"1PsIzgvUlhhrzXoDBJe8pKOcvDzG1LV_u","timestamp":1730061729075},{"file_id":"1cnvAjO9vtlesY7n3NOF26A121p28rpNO","timestamp":1729883746816}],"authorship_tag":"ABX9TyPWZ5gsbKB01Y5B5p7DordY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAHd-l3h4MpT","executionInfo":{"status":"ok","timestamp":1730839845679,"user_tz":180,"elapsed":2934,"user":{"displayName":"Marce Fernandez","userId":"15767534137049977305"}},"outputId":"ec986018-b0ac-404d-f76e-00830d4d0a16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5  # Descargar YOLOv5\n","%cd yolov5\n","!pip install -r requirements.txt  # Instalar las dependencias"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzCID-Aa4rob","executionInfo":{"status":"ok","timestamp":1730839853185,"user_tz":180,"elapsed":7525,"user":{"displayName":"Marce Fernandez","userId":"15767534137049977305"}},"outputId":"9c9c8f56-5951-42d6-f6ee-0ee90ae74dca"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 17022, done.\u001b[K\n","remote: Total 17022 (delta 0), reused 0 (delta 0), pack-reused 17022 (from 1)\u001b[K\n","Receiving objects: 100% (17022/17022), 15.61 MiB | 19.33 MiB/s, done.\n","Resolving deltas: 100% (11690/11690), done.\n","/content/yolov5/yolov5\n","Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.43)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n","Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (10.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.5.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.20.0+cu121)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.6)\n","Requirement already satisfied: ultralytics>=8.2.34 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.3.27)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n","Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (75.1.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.10)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw\n","import cv2\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Definir rutas en Google Drive (asegúrate de que las carpetas contengan imágenes)\n","train_dir = '/content/drive/MyDrive/Strawberry Disease Detection Dataset-Usman afzaal/train/images'\n","test_dir = '/content/drive/MyDrive/Strawberry Disease Detection Dataset-Usman afzaal/test/images'\n","val_dir = '/content/drive/MyDrive/Strawberry Disease Detection Dataset-Usman afzaal/val/images'\n","severity_dir = '/content/drive/MyDrive/Strawberry Disease Detection Dataset-Usman afzaal/Test Disease Severity Level'\n","\n","# Crear directorios de salida si no existen\n","output_train = '/content/drive/MyDrive/YOLOv5_Annotations/train'\n","output_test = '/content/drive/MyDrive/YOLOv5_Annotations/test'\n","output_val = '/content/drive/MyDrive/YOLOv5_Annotations/val'\n","\n","os.makedirs(output_train, exist_ok=True)\n","os.makedirs(output_test, exist_ok=True)\n","os.makedirs(output_val, exist_ok=True)"],"metadata":{"id":"7pvLa_vw4zLi","executionInfo":{"status":"ok","timestamp":1730839853186,"user_tz":180,"elapsed":64,"user":{"displayName":"Marce Fernandez","userId":"15767534137049977305"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Celda n2: Funciones para lectura y generación de máscaras\n","def read_polygon_coordinates_and_label_from_json(json_path):\n","    with open(json_path) as f:\n","        data = json.load(f)\n","    polygons = data[\"shapes\"]\n","    coordinates = []\n","    labels = []\n","    for polygon in polygons:\n","        points = polygon[\"points\"]\n","        label = polygon[\"label\"]\n","        coordinates.append(points)\n","        labels.append(label)\n","    return coordinates, labels\n","\n","def generate_masks(image_size, coordinates):\n","    combined_mask = np.zeros(image_size, dtype=np.uint8)\n","    for points in coordinates:\n","        points = [(int(x), int(y)) for (x, y) in points]\n","        if not all(isinstance(point, tuple) and len(point) == 2 for point in points):\n","            print(\"Coordenadas no válidas:\", points)\n","            continue\n","        mask = Image.new(\"L\", image_size, 0)\n","        ImageDraw.Draw(mask).polygon(points, outline=1, fill=1)\n","        combined_mask = np.maximum(combined_mask, np.array(mask))\n","    return combined_mask\n","\n","def check_image_mask_paths(image_paths, mask_paths):\n","    print(f\"Cantidad de imágenes: {len(image_paths)}\")\n","    print(f\"Cantidad de máscaras: {len(mask_paths)}\")\n","    for img_path in image_paths:\n","        print(f\"Imagen: {img_path}\")\n","        mask_path = img_path.replace('images', 'masks').replace('.jpg', '.png')\n","        print(f\"Máscara esperada: {mask_path}\")\n","        if not os.path.exists(mask_path):\n","            print(f\"Máscara no encontrada: {mask_path}\")\n","    assert len(image_paths) == len(mask_paths), \"La cantidad de imágenes y máscaras no coincide.\"\n","\n","def get_image_paths_masks_and_labels(directory):\n","    image_paths = []\n","    masks = []\n","    labels = []\n","    for image_path in glob.glob(os.path.join(directory, \"*.jpg\")):\n","        json_path = image_path.replace(\".jpg\", \".json\")\n","        if os.path.exists(json_path):\n","            coordinates, label = read_polygon_coordinates_and_label_from_json(json_path)\n","            image = Image.open(image_path)\n","            image_size = image.size\n","            image_paths.append(image_path)\n","            masks.append(generate_masks(image_size, coordinates))\n","            labels.append(label)\n","    return image_paths, masks, labels\n","\n","def get_image_paths_masks_labels_and_severity(directory):\n","    image_paths = []\n","    masks = []\n","    labels = []\n","    severities = []\n","    for severity_level in [\"Level 1\", \"Level 2\"]:\n","        level_dir = os.path.join(directory, severity_level)\n","        for image_path in glob.glob(os.path.join(level_dir, \"*.jpg\")):\n","            json_path = image_path.replace(\".jpg\", \".json\")\n","            if os.path.exists(json_path):\n","                coordinates, label = read_polygon_coordinates_and_label_from_json(json_path)\n","                image = Image.open(image_path)\n","                image_size = image.size\n","                image_paths.append(image_path)\n","                masks.append(generate_masks(image_size, coordinates))\n","                labels.append(label)\n","                severities.append(severity_level)\n","    return image_paths, masks, labels, severities"],"metadata":{"id":"TtTUSHUE5hPN","executionInfo":{"status":"ok","timestamp":1730839853187,"user_tz":180,"elapsed":60,"user":{"displayName":"Marce Fernandez","userId":"15767534137049977305"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Celda n3: Dataset de frutillas con transformaciones\n","import os\n","import json\n","from PIL import Image, ImageDraw\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","data_transforms = transforms.Compose([\n","    transforms.Resize((640, 640)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","mask_transforms = transforms.Compose([\n","    transforms.Resize((640, 640)),\n","    transforms.ToTensor()\n","])\n","\n","def draw_mask_on_image(image, mask_json):\n","    draw = ImageDraw.Draw(image)\n","    for region in mask_json['shapes']:\n","        points = region['points']\n","        polygon_coords = [(int(x), int(y)) for x, y in points]\n","        draw.polygon(polygon_coords, outline=None, fill=255)\n","    return image\n","\n","class StrawberryDataset(Dataset):\n","    def __init__(self, image_dir, mask_dir, image_transforms=None, mask_transforms=None):\n","        self.image_dir = image_dir\n","        self.mask_dir = mask_dir\n","        self.image_transforms = image_transforms\n","        self.mask_transforms = mask_transforms\n","\n","        # Crear un diccionario con los nombres de los archivos de imagen sin extensión\n","        image_files = {f.split(\".\")[0]: f for f in os.listdir(image_dir) if f.endswith('.jpg')}\n","        mask_files = {f.split(\".\")[0]: f for f in os.listdir(mask_dir) if f.endswith('.json')}\n","\n","        # Solo quedarnos con los archivos que tienen tanto imagen como máscara\n","        common_files = image_files.keys() & mask_files.keys()\n","\n","        # Depuración: Imprimir información sobre los archivos\n","        print(f\"Total de archivos de imagen: {len(image_files)}\")\n","        print(f\"Total de archivos de máscara: {len(mask_files)}\")\n","        print(f\"Archivos comunes: {len(common_files)}\")\n","\n","        # Crear listas de paths para imágenes y máscaras correspondientes\n","        self.image_paths = [os.path.join(image_dir, image_files[f]) for f in common_files]\n","        self.mask_paths = [os.path.join(mask_dir, mask_files[f]) for f in common_files]\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        # Cargar la imagen y la máscara\n","        image_path = self.image_paths[idx]\n","        mask_path = self.mask_paths[idx]\n","\n","        # Cargar la imagen y aplicar transformaciones\n","        image = Image.open(image_path).convert(\"RGB\")\n","        if self.image_transforms:\n","            image = self.image_transforms(image)\n","\n","        # Cargar la máscara desde el archivo JSON\n","        with open(mask_path, 'r') as f:\n","            mask_data = json.load(f)\n","\n","        # Crear una imagen en blanco para la máscara (del mismo tamaño que la imagen)\n","        mask = Image.new('L', (image.width, image.height))\n","        draw = ImageDraw.Draw(mask)\n","\n","        # Dibujar la máscara basada en los puntos del archivo JSON\n","        for shape in mask_data['shapes']:\n","            points = shape['points']\n","            draw.polygon(points, outline=1, fill=1)\n","\n","        if self.mask_transforms:\n","            mask = self.mask_transforms(mask)\n","\n","        return image, mask\n","\n","# Nueva función: preparar_targets para YOLOv5\n","def preparar_targets(masks, image_size):\n","    targets = []\n","    for mask in masks:\n","        mask = mask.numpy()  # Convertir el tensor de PyTorch a numpy\n","        object_indices = np.where(mask == 1)\n","        if len(object_indices[0]) > 0:\n","            x_min, x_max = np.min(object_indices[1]), np.max(object_indices[1])\n","            y_min, y_max = np.min(object_indices[0]), np.max(object_indices[0])\n","            # Normalizar las coordenadas\n","            bbox = [x_min / image_size[0], y_min / image_size[1], x_max / image_size[0], y_max / image_size[1]]\n","            targets.append(bbox)\n","        else:\n","            targets.append([0, 0, 0, 0])  # Si no hay objeto, añades un bbox vacío\n","    return torch.tensor(targets, dtype=torch.float32)\n"],"metadata":{"id":"OyvVArPqAMuy","executionInfo":{"status":"ok","timestamp":1730839853187,"user_tz":180,"elapsed":57,"user":{"displayName":"Marce Fernandez","userId":"15767534137049977305"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Ruta de la carpeta de las máscaras\n","mask_dir = '/content/drive/MyDrive/Strawberry Disease Detection Dataset-Usman afzaal/train/masks'\n","\n","# Listar los archivos en la carpeta de máscaras\n","mask_files = [f for f in os.listdir(mask_dir) if f.endswith('.json')]\n","\n","# Depuración: Mostrar los primeros 10 archivos en la carpeta de máscaras\n","print(f\"Total de archivos de máscara: {len(mask_files)}\")\n","print(\"Algunos archivos de máscara:\", mask_files[:10])\n","\n","# Verifica si hay archivos con extensión \".JSON\" en mayúsculas\n","mask_files_upper = [f for f in os.listdir(mask_dir) if f.endswith('.JSON')]\n","print(f\"Total de archivos de máscara con .JSON en mayúsculas: {len(mask_files_upper)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gtmhFLRytoWk","executionInfo":{"status":"ok","timestamp":1730839853188,"user_tz":180,"elapsed":55,"user":{"displayName":"Marce Fernandez","userId":"15767534137049977305"}},"outputId":"177aa528-5b26-4348-ee16-b462be45ec67"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de archivos de máscara: 1450\n","Algunos archivos de máscara: ['blossom_blight89.json', 'gray_mold235.json', 'gray_mold120.json', 'gray_mold129.json', 'gray_mold217.json', 'blossom_blight83.json', 'gray_mold221.json', 'gray_mold139.json', 'gray_mold23.json', 'blossom_blight99.json']\n","Total de archivos de máscara con .JSON en mayúsculas: 0\n"]}]},{"cell_type":"code","source":["# Celda n4: Modelo de entrenamiento\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import joblib\n","import os\n","\n","from models.yolo import Model as YOLOv5\n","\n","total_epochs = 60\n","batch_size = 10\n","\n","model = YOLOv5(cfg='/content/yolov5/models/yolov5s.yaml')\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","def train_model(model, train_loader, val_loader, total_epochs, device):\n","    model.to(device)\n","    for epoch in range(total_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for i, (images, masks) in enumerate(train_loader):\n","            images = images.to(device)\n","            masks = masks.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            targets = preparar_targets(masks, images.shape[2:])\n","            targets = targets.to(device)\n","            total_loss = criterion(outputs, targets.float())\n","            total_loss.backward()\n","            optimizer.step()\n","            running_loss += total_loss.item()\n","        print(f\"Época {epoch+1}/{total_epochs}, Pérdida: {running_loss / len(train_loader)}\")\n","        val_loss = 0.0\n","        model.eval()\n","        with torch.no_grad():\n","            for images, masks in val_loader:\n","                images = images.to(device)\n","                masks = masks.to(device)\n","                outputs = model(images)\n","                targets = preparar_targets(masks, images.shape[2:])\n","                targets = targets.to(device)\n","                loss = criterion(outputs, targets.float())\n","                val_loss += loss.item()\n","        print(f\"Pérdida de validación: {val_loss / len(val_loader)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpHVGuuQybFQ","executionInfo":{"status":"ok","timestamp":1730839853638,"user_tz":180,"elapsed":501,"user":{"displayName":"Marce Fernandez","userId":"15767534137049977305"}},"outputId":"9c84824f-b572-4f38-c30b-5a125d109462"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n","\n"]}]},{"cell_type":"code","source":["# Definir las rutas para los directorios de imágenes y máscaras\n","train_image_dir = '/content/drive/MyDrive/Strawberry Disease Detection Dataset-Usman afzaal/train/images'\n","train_mask_dir = '/content/drive/MyDrive/Strawberry Disease Detection Dataset-Usman afzaal/train/masks'\n","\n","val_image_dir = '/content/drive/MyDrive/Strawberry Disease Detection Dataset-Usman afzaal/val/images'\n","val_mask_dir = '/content/drive/MyDrive/Strawberry Disease Detection Dataset-Usman afzaal/val/masks'\n","\n","# Crear los datasets de entrenamiento y validación\n","train_dataset = StrawberryDataset(train_image_dir, train_mask_dir, image_transforms=data_transforms, mask_transforms=mask_transforms)\n","val_dataset = StrawberryDataset(val_image_dir, val_mask_dir, image_transforms=data_transforms, mask_transforms=mask_transforms)\n","\n","# Crear los DataLoader para cargar los datos en lotes\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pvgS3yBzHxQ","executionInfo":{"status":"ok","timestamp":1730839854094,"user_tz":180,"elapsed":465,"user":{"displayName":"Marce Fernandez","userId":"15767534137049977305"}},"outputId":"3e7149f7-8598-49a1-ab3b-66eafe88875d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de archivos de imagen: 1450\n","Total de archivos de máscara: 1450\n","Archivos comunes: 1450\n","Total de archivos de imagen: 307\n","Total de archivos de máscara: 307\n","Archivos comunes: 307\n"]}]},{"cell_type":"code","source":["import os\n","import joblib\n","\n","# Definir la ruta donde guardar el modelo\n","save_dir = \"/content/drive/MyDrive/YOLOv5_Models\"\n","\n","# Verificar si el directorio existe, si no, crearlo\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","\n","# Guardar el modelo\n","model_path = os.path.join(save_dir, \"strawberry_model_v2.pth\")\n","joblib.dump(model.state_dict(), model_path)\n","\n","print(f\"Modelo guardado en: {model_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zpIOdDHADkI","executionInfo":{"status":"ok","timestamp":1730839854739,"user_tz":180,"elapsed":660,"user":{"displayName":"Marce Fernandez","userId":"15767534137049977305"}},"outputId":"0571d41a-1c23-4064-ffdd-96580c014bcb"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Modelo guardado en: /content/drive/MyDrive/YOLOv5_Models/strawberry_model_v2.pth\n"]}]}]}